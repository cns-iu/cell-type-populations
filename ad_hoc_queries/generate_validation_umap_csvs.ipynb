{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to generate 1 CSV file for UMAPs (by intersection percentage with anatomical structures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hra_pop_version = \"0.9.0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_reference_organ(reference_organ, as_label):\n",
    "    \"\"\"removes a set of predefined strings form a reference organ and returns a column header\n",
    "\n",
    "    Args:\n",
    "        reference_organ (string): an IRI for an organ\n",
    "        as_label (_type_): a human readable label for an anatomical structure\n",
    "\n",
    "    Returns:\n",
    "        header (string): a column header\n",
    "    \"\"\"\n",
    "    to_remove = ['VHF', 'VHM']\n",
    "    pattern = \"|\".join(map(re.escape, to_remove))\n",
    "    organ = re.sub(pattern,'', reference_organ)\n",
    "    # header = f'{organ} - {as_label}'\n",
    "    header = f'{as_label}'\n",
    "    return header\n",
    "\n",
    "def get_partial_match_key(header, partial_string):\n",
    "    \"\"\"Returns a key given a match with a partial string\n",
    "\n",
    "    Args:\n",
    "        dict (string): a header\n",
    "        partial_string (string): a partial key\n",
    "\n",
    "    Returns:\n",
    "        key (if match found): a full key that matches the partial string argument\n",
    "    \"\"\"\n",
    "    if partial_string in header:\n",
    "        return header\n",
    "    return None  # Return None if no partial match is found\n",
    "\n",
    "def remove_version(input_string):\n",
    "    \"\"\"Removes the version from a reference organ\n",
    "\n",
    "    Args:\n",
    "        input_string (string): the reference organ with version\n",
    "\n",
    "    Returns:\n",
    "        string : the reference organ without version\n",
    "    \"\"\"\n",
    "    return re.sub(r'V\\d+(\\.\\d+)?', '', input_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load enriched-dataset-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Link to atlas-enriched-dataset-graph\n",
    "atlas_enriched_dataset_graph_file = open(\"../../hra-pop/output-data/v\"+hra_pop_version+ \"/atlas-enriched-dataset-graph.jsonld\") # biomarkers and cell types\n",
    "\n",
    "# Opening Jthe JSON-LD file\n",
    "dataset_graph = json.load(atlas_enriched_dataset_graph_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize result, to be converted to pandas data farme at the end and exported as CSV\n",
    "result = {\n",
    "'dataset_id' : [],\n",
    "'dataset_combinations' : [],\n",
    "'organ' : [],\n",
    "'as_item_combinations' : []\n",
    "}\n",
    "\n",
    "# dynamically construct columns for output, where each AS is one column\n",
    "for donor in dataset_graph['@graph']:\n",
    "  for sample in donor['samples']:\n",
    "    for collision_summary in sample['rui_location']['all_collisions']:\n",
    "      for collision_item in collision_summary['collisions']:\n",
    "        as_label = collision_item['as_label']\n",
    "        \n",
    "        # construct AS column header\n",
    "        header = strip_reference_organ(remove_version(collision_item['reference_organ'].split('#')[1]), as_label)\n",
    "        \n",
    "        # add header if not present yet\n",
    "        if header not in result:\n",
    "          result[header] = []\n",
    "\n",
    "# fill in columns\n",
    "for donor in dataset_graph['@graph']:\n",
    "  for sample in donor['samples']:\n",
    "    \n",
    "    # get all datasets in sample\n",
    "    datasets_in_sample = []\n",
    "    \n",
    "    # get dataset IDs from sample\n",
    "    for dataset in sample['datasets']:\n",
    "      result['dataset_id'].append(dataset['@id'])\n",
    "      datasets_in_sample.append(dataset['@id'])\n",
    "    \n",
    "    # get dataset IDs from section\n",
    "    for section in sample['sections']:\n",
    "      for dataset in section['datasets']:\n",
    "        result['dataset_id'].append(dataset['@id'])\n",
    "        datasets_in_sample.append(dataset['@id'])\n",
    "\n",
    "    # get organ\n",
    "    result['organ'].append(remove_version(sample['rui_location']['placement']['target'].split('#')[1]))\n",
    "    \n",
    "    # get AS percentages\n",
    "    for collision_summary in sample['rui_location']['all_collisions']:\n",
    "      result['dataset_combinations'].append(datasets_in_sample)\n",
    "      \n",
    "      # get simplified collision items\n",
    "      as_items = []\n",
    "      \n",
    "      for collision_item in collision_summary['collisions']:\n",
    "        as_items.append(\n",
    "          {\n",
    "            'label': collision_item['as_label'],\n",
    "            'percentage': collision_item['percentage']\n",
    "          }\n",
    "        )\n",
    "\n",
    "      result['as_item_combinations'].append(as_items)\n",
    "    \n",
    "    # define columns to ignore\n",
    "    ignore_columns = [\"dataset_id\", \"organ\", \"dataset_combinations\", \"as_item_combinations\"]\n",
    "\n",
    "    # add 0 as default AS collision percentage to AS columns\n",
    "    for key in result:\n",
    "      if key in ignore_columns:\n",
    "       continue\n",
    "      else:\n",
    "        result[key].append(0)\n",
    "\n",
    "# identify as_item_combinations with the same value\n",
    "multiple_as_item_combinations = {}\n",
    "\n",
    "for row in result['as_item_combinations']:\n",
    " if str(row) not in multiple_as_item_combinations:\n",
    "   multiple_as_item_combinations[str(row)] = {\n",
    "     'occurences' : 1,\n",
    "     'current_index' : 0,\n",
    "     'indices_in_rows' : []\n",
    "     }\n",
    " else:\n",
    "   multiple_as_item_combinations[str(row)]['occurences'] = multiple_as_item_combinations[str(row)]['occurences'] + 1\n",
    "  #  multiple_as_item_combinations[str(row)]['indices_in_rows'] = [index for index, value in enumerate(result['as_item_combinations']) if value == row]\n",
    "   multiple_as_item_combinations[str(row)]['indices_in_rows'] = [index for index, value in enumerate(result['as_item_combinations']) if str(value) == str(row)]\n",
    "\n",
    "for row in list(multiple_as_item_combinations.keys()):\n",
    "  if multiple_as_item_combinations[str(row)]['occurences'] == 1:\n",
    "    del multiple_as_item_combinations[str(row)]\n",
    "\n",
    "# fill in cells with percentages (overwriting default: 0)\n",
    "index_by_row = {}\n",
    "for row in result[\"as_item_combinations\"]:\n",
    "  current = index_by_row.setdefault(str(row), 0)\n",
    "  index_by_row[str(row)] += 1\n",
    "  for key in result:\n",
    "    if key in ignore_columns:\n",
    "      continue\n",
    "    for item in row:\n",
    "      if item['label'] == key:\n",
    "\n",
    "      # ALWAYS RETURNS INDEX OF FIRST OCCURENCE! NEED TO ACCOUNT FOR ROWS WITH SAME VALUES!\n",
    "      # check if row occurs multiple times\n",
    "        for multiple_combo in multiple_as_item_combinations:\n",
    "          if str(row) == multiple_combo:\n",
    "\n",
    "            i_in_row = multiple_as_item_combinations[str(row)]['indices_in_rows'][current]\n",
    "\n",
    "\n",
    "          else:\n",
    "            i_in_row = result['as_item_combinations'].index(row)\n",
    "\n",
    "          result[key][i_in_row] = item['percentage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns before export\n",
    "result.pop('dataset_id')\n",
    "\n",
    "df = pd.DataFrame.from_dict(result)\n",
    "\n",
    "# # Export DataFrame to CSV\n",
    "df.to_csv('output/umap_as_percentage.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
